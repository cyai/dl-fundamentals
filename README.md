# Deep Learning Fundamentals from Scratch

Welcome to the Deep Learning Fundamentals from Scratch repository! This repository is designed to help you understand the fundamental concepts of deep learning by building them from scratch. Currently, it contains the implementation of the perceptron from scratch, but more concepts will be added gradually.

## Table of Contents

- [Perceptron](#perceptron)
- [Neural Networks](#neural-networks)
- [Gradient Descent](#gradient-descent)
- [Activation Functions](#activation-functions)
- [Backpropagation](#backpropagation)
- [Feedforward Neural Networks](#feedforward-neural-networks)
- [Convolutional Neural Networks (CNNs)](#convolutional-neural-networks-cnns)
- [Recurrent Neural Networks (RNNs)](#recurrent-neural-networks-rnns)
- [Generative Adversarial Networks (GANs)](#generative-adversarial-networks-gans)

## Perceptron

The perceptron is one of the simplest building blocks of neural networks. It's a binary linear classifier that can be used for tasks like binary classification. In this repository, you can find the Python code for implementing a perceptron from scratch.

- [Perceptron Implementation](perceptron/perceptron.py): This Python script contains the code for a simple perceptron.

## Neural Networks

Neural networks are the foundation of deep learning. We will be covering various aspects of neural networks, including architecture, training, and optimization.

## Gradient Descent

Gradient descent is a key optimization algorithm used to update the parameters of neural networks to minimize the loss function.

## Activation Functions

Activation functions are used to introduce non-linearity into neural networks, allowing them to learn complex patterns.

## Backpropagation

Backpropagation is the algorithm used to calculate gradients and update the neural network's weights during training.

## Feedforward Neural Networks

Feedforward neural networks, also known as multi-layer perceptrons (MLPs), are the most basic type of neural network architecture.

## Convolutional Neural Networks (CNNs)

Convolutional Neural Networks (CNNs) are designed for tasks involving images and spatial data.

## Recurrent Neural Networks (RNNs)

Recurrent Neural Networks (RNNs) are used for sequential data tasks, such as natural language processing and time series analysis.

## Generative Adversarial Networks (GANs)

Generative Adversarial Networks (GANs) are a type of neural network used for generative tasks, such as image generation.

Stay tuned as we add more content and code examples to help you understand these deep learning concepts from scratch! Feel free to explore the existing code and tutorials, and don't hesitate to reach out if you have any questions or suggestions. Happy learning!

**Note:** Please make sure you have the required dependencies installed to run the code examples in this repository. Instructions for setting up the environment will be provided in each respective folder as we add more content.
